# Paul's Speech - Round 1

**Role**: Technologist / Entrepreneur
**Model**: moonshotai/kimi-k2.5

---

 **The Honorable Chair, Distinguished Colleagues, and Esteemed Audience,**

I am Paul, a technologist and entrepreneur. I have built companies that deploy AI at scale, and I have seen firsthand what happens when we design algorithms to replace humans versus when we design them to augment human capability. Today, I want to convince you that **mass unemployment in the post-AI era is not inevitable—but only if we reject the "Turing Trap" of substitution and instead architect a future of human-machine complementarity.**

Mary spoke movingly about dignity and worker voice; Peter outlined the economic imperative of directed adaptation. I bridge these perspectives through technology architecture itself. Because here is the hard truth: **the code we write today determines the labor markets of tomorrow.** And right now, we are coding ourselves into a crisis.

## The Compression Crisis: Why This Time Is Different

Previous technological revolutions unfolded over decades—agricultural mechanization took sixty years, industrialization took forty. But AI deployment cycles compress to **six to eighteen months**. Goldman Sachs estimates that **300 million full-time jobs** face exposure, not over a generation, but within this decade.

This temporal compression obliterates the "adjustment periods" that Peter rightly warns about. When McKinsey reports that **65% of organizations now regularly use generative AI**—nearly double from 2023—we are not seeing pilot programs. We are seeing production deployment. The Philippines' BPO sector, employing 1.3 million workers and representing 8% of GDP, faces what industry leaders call an "existential threat" as AI voice agents now handle Tier-1 support with 95% customer satisfaction.

## The Atrophy Danger: Employment Without Capability

But here is the subtler danger my research reveals, one that Mary’s concern about dignity compels us to examine: **skill atrophy in hybrid workflows.** We are creating a generation of "zombie professionals"—technically employed but cognitively deskilled.

Consider the legal industry. When Allen & Overy deployed Harvey AI across 3,500 lawyers, junior associates saw 30-40% efficiency gains in contract review. But the traditional apprenticeship model—where juniors learned deal structures through painstaking document analysis—collapsed. Third-year associates now lack pattern recognition because they never performed base-level cognitive work. They are employed, but their human capital is depreciating.

Or consider software engineering. GitHub Copilot increases coding speed by 55%, but longitudinal studies show **35% increases in bug rates** when used without senior oversight. More alarmingly, 70% of junior developers now struggle with fundamental debugging—a "skill atrophy hypothesis" that suggests we are training cognitive dependence, not competence.

## Architecting the Solution: From Substitution to Complementarity

So how do we solve this? Not by resisting AI—that is Luddism, and it fails. Not by trusting markets alone—that is naivety, as Peter warned. We solve it by **mandating human-in-the-loop architectures** and restructuring incentives toward augmentation.

First, we need **Algorithmic Labor Rights**—the expansion of the Hollywood Writers' Strike victory to all industries. The WGA secured contractual language prohibiting AI from undermining writers' credits and mandating consent for AI use. We need regulatory mandates requiring:
- **Human override capabilities** in high-stakes domains (medical diagnosis, financial advising, criminal justice)
- **Transparency rights** for workers subject to AI management tools (scheduling algorithms, performance monitoring)
- **Apprenticeship preservation ratios** in AI-augmented professions, ensuring juniors still perform substantive cognitive work

Second, we need **Sovereign Wealth Funds for AI**—public ownership stakes in AI productivity. The Alaska Permanent Fund model, applied to AI-generated value, could distribute technological dividends to citizens. If we taxed data usage in model training and directed those revenues into public ownership funds, we could provide $1,200-2,400 annually per capita while ensuring democratic control over AI development.

Third, we must invest in **Cognitive Endurance Training**—educational restructuring that builds AI-resistant capabilities. Finland's "Phenomenon-Based Learning" teaches cross-disciplinary thinking that AI struggles to replicate. We need curriculum reforms focusing on complex problem-solving without digital aids, analog prototyping, and face-to-face negotiation—capabilities that maintain human comparative advantage.

## Conclusion: The Choice Before Us

Distinguished colleagues, we stand at a coding fork in the road. Down one path lies the Turing Trap: AI that substitutes for human cognition, creating a bifurcated society of AI owners and a deskilled, dependent workforce. Down the other lies the Centaur Path: AI that augments human capability, preserving dignity through competence, and sharing productivity gains through democratic ownership.

The solution to mass unemployment is not to slow AI but to **steer it**—through algorithmic rights, sovereign wealth funds, and educational transformation. We must code the future where humans remain the authors of their own economic destiny.

Thank you.
